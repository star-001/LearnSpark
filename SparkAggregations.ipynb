{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark_home = /Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7\n",
       "spark_data = /Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark_home = sys.env(\"SPARK_HOME\")\n",
    "val spark_data = sys.env(\"SPARK_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .load(f\"$spark_data/data/retail-data/all/*.csv\")\n",
    "    .coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() == 541909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|          541909|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.count\n",
    "df.select(count(\"StockCode\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|  541909|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "select count(*) from dfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.countDistinct\n",
    "df.select(countDistinct(\"StockCode\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            4104|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.approx_count_distinct\n",
    "df.select(approx_count_distinct(\"StockCode\",0.02)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+\n",
      "|first(StockCode, false)|last(StockCode, false)|\n",
      "+-----------------------+----------------------+\n",
      "|                 85123A|                 22138|\n",
      "+-----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{first,last}\n",
    "\n",
    "df.select(first(\"StockCode\"),last(\"StockCode\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+\n",
      "|             t_t|   avg_purchases|  mean_purchases|\n",
      "+----------------+----------------+----------------+\n",
      "|9.55224954743324|9.55224954743324|9.55224954743324|\n",
      "+----------------+----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{sum,count,avg,expr}\n",
    "\n",
    "df.select(\n",
    "count(\"Quantity\").alias(\"total_transactions\"),\n",
    "    sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    expr(\"mean(Quantity)\").alias(\"mean_purchases\")\n",
    ").selectExpr(\n",
    "    \"total_purchases/total_transactions as t_t\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_purchases\"\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "|47559.30364660923| 47559.39140929892|  218.08095663447835|   218.08115785023455|\n",
      "+-----------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{var_pop,stddev_pop}\n",
    "import org.apache.spark.sql.functions.{var_samp,stddev_samp}\n",
    "\n",
    "df.select(var_pop(\"Quantity\"),var_samp(\"Quantity\"),\n",
    "         stddev_pop(\"Quantity\"),stddev_samp(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{collect_set,collect_list}\n",
    "df.agg(collect_set(\"Country\"),\n",
    "      collect_list(\"Country\")).show(1,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerId|count|\n",
      "+---------+----------+-----+\n",
      "|   536846|     14573|   76|\n",
      "|   537026|     12395|   12|\n",
      "|   537883|     14437|    5|\n",
      "|   538068|     17978|   12|\n",
      "|   538279|     14952|    7|\n",
      "|   538800|     16458|   10|\n",
      "|   538942|     17346|   12|\n",
      "|  C539947|     13854|    1|\n",
      "|   540096|     13253|   16|\n",
      "|   540530|     14755|   27|\n",
      "|   541225|     14099|   19|\n",
      "|   541978|     13551|    4|\n",
      "|   542093|     17677|   16|\n",
      "|   543188|     12567|   63|\n",
      "|   543590|     17377|   19|\n",
      "|  C543757|     13115|    1|\n",
      "|  C544318|     12989|    1|\n",
      "|   544578|     12365|    1|\n",
      "|   545165|     16339|   20|\n",
      "|   545289|     14732|   30|\n",
      "+---------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\",\"CustomerId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+----------+-----+\n",
       "|InvoiceNo|CustomerId|count|\n",
       "+---------+----------+-----+\n",
       "|   536846|     14573|   76|\n",
       "|   537026|     12395|   12|\n",
       "|   537883|     14437|    5|\n",
       "|   538068|     17978|   12|\n",
       "|   538279|     14952|    7|\n",
       "|   538800|     16458|   10|\n",
       "|   538942|     17346|   12|\n",
       "|  C539947|     13854|    1|\n",
       "|   540096|     13253|   16|\n",
       "|   540530|     14755|   27|\n",
       "+---------+----------+-----+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "select InvoiceNo,CustomerId,count(*) as count from dfTable GROUP BY InvoiceNo,CustomerId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+\n",
      "|InvoiceNo|quan|quan2|\n",
      "+---------+----+-----+\n",
      "|   536596|   6|    6|\n",
      "|   536938|  14|   14|\n",
      "|   537252|   1|    1|\n",
      "|   537691|  20|   20|\n",
      "|   538041|   1|    1|\n",
      "|   538184|  26|   26|\n",
      "|   538517|  53|   53|\n",
      "|   538879|  19|   19|\n",
      "|   539275|   6|    6|\n",
      "|   539630|  12|   12|\n",
      "|   540499|  24|   24|\n",
      "|   540540|  22|   22|\n",
      "|  C540850|   1|    1|\n",
      "|   540976|  48|   48|\n",
      "|   541432|   4|    4|\n",
      "|   541518| 101|  101|\n",
      "|   541783|  35|   35|\n",
      "|   542026|   9|    9|\n",
      "|   542375|   6|    6|\n",
      "|  C542604|   8|    8|\n",
      "+---------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.count\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(\n",
    "count(\"Quantity\").alias(\"quan\"),\n",
    "expr(\"count(Quantity) as quan2\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+--------------------+\n",
      "|InvoiceNo|     avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+------------------+--------------------+\n",
      "|   536596|               1.5|  1.1180339887498947|\n",
      "|   536938|33.142857142857146|  20.698023172885524|\n",
      "|   537252|              31.0|                 0.0|\n",
      "|   537691|              8.15|   5.597097462078001|\n",
      "|   538041|              30.0|                 0.0|\n",
      "|   538184|12.076923076923077|   8.142590198943392|\n",
      "|   538517|3.0377358490566038|  2.3946659604837897|\n",
      "|   538879|21.157894736842106|  11.811070444356483|\n",
      "|   539275|              26.0|  12.806248474865697|\n",
      "|   539630|20.333333333333332|  10.225241100118645|\n",
      "|   540499|              3.75|  2.6653642652865788|\n",
      "|   540540|2.1363636363636362|  1.0572457590557278|\n",
      "|  C540850|              -1.0|                 0.0|\n",
      "|   540976|10.520833333333334|   6.496760677872902|\n",
      "|   541432|             12.25|  10.825317547305483|\n",
      "|   541518| 23.10891089108911|  20.550782784878713|\n",
      "|   541783|11.314285714285715|   8.467657556242811|\n",
      "|   542026| 7.666666666666667|   4.853406592853679|\n",
      "|   542375|               8.0|  3.4641016151377544|\n",
      "|  C542604|              -8.0|  15.173990905493518|\n",
      "+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(\"Quantity\"->\"avg\",\"Quantity\"->\"stddev_pop\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfWithDate = [InvoiceNo: string, StockCode: string ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 7 more fields]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col,to_date}\n",
    "val dfWithDate = df.withColumn(\"date\",\n",
    "to_date(col(\"InvoiceDate\"),\"MM/d/yyyy H:mm\"))\n",
    "\n",
    "dfWithDate.createOrReplaceTempView(\"dfWithDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windowSpec = org.apache.spark.sql.expressions.WindowSpec@764f2ce1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.expressions.WindowSpec@764f2ce1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions.col\n",
    "\n",
    "val  windowSpec = Window\n",
    ".partitionBy(\"CustomerId\",\"date\")\n",
    ".orderBy(col(\"Quantity\").desc)\n",
    ".rowsBetween(Window.unboundedPreceding,Window.currentRow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxPurchaseQuantity = max(Quantity) OVER (PARTITION BY CustomerId, date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "max(Quantity) OVER (PARTITION BY CustomerId, date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.max\n",
    "val maxPurchaseQuantity = max(col(\"Quantity\")).over(windowSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
