{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark_home = /Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7\n",
       "data_path = /Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7/data\n",
       "df_path = /Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7/data/retail-data/by-day/2010-12-01.csv\n",
       "df = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col,lit,expr}\n",
    "val spark_home = \"/Users/fanzhenxin/bigData/spark-2.4.4-bin-hadoop2.7\"\n",
    "val data_path = spark_home+\"/data\"\n",
    "val df_path = data_path+\"/retail-data/by-day/2010-12-01.csv\"\n",
    "val df = spark.read.format(\"csv\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .load(df_path)\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.coalesce\n",
    "\n",
    "//df.select(coalesce(col(\"Description\"),\n",
    "//                  col(\"CustomerId\"))).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------------+----+------------+----------+\n",
       "|           a|   b|           c|         d|\n",
       "+------------+----+------------+----------+\n",
       "|return_value|null|return_value|else_value|\n",
       "+------------+----+------------+----------+\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "SELECT\n",
    "ifnull(null,'return_value') a,\n",
    "nullif('value','value') b,\n",
    "nvl(null,'return_value') c,\n",
    "nvl2(null,'return_value','else_value') d\n",
    "from dfTable LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"All Null values become this string\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3108\n",
      "1968\n"
     ]
    }
   ],
   "source": [
    "println(df.count())\n",
    "println(df.na.drop(\"any\",Seq(\"CustomerID\")).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nullDF = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nullDF = df.filter('CustomerID.isNull)\n",
    "\n",
    "// nullDF.na.fill(\"any\",\"NA Value\")\n",
    "// .select(\"InvoiceNo\",\"StockCode\",\"Description\",\"CustomerID\")\n",
    "// .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"TEST\").where(col(\"CustomerID\").isNull).select(\"CustomerID\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "|     100.0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2 = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.na.fill(100:Double,Seq(\"CustomerID\"))\n",
    "df2.where(col(\"CustomerID\")===100)\n",
    ".select(\"CustomerID\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|CustomerID|\n",
      "+----------+\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fillColValues = Map(CustomerID -> NullVal)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(CustomerID -> NullVal)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fillColValues = Map(\"CustomerID\"->\"NullVal\")\n",
    "df.na.fill(fillColValues).select(\"CustomerID\").where(col(\"CustomerID\")===\"NullVal\")\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Description|\n",
      "+-----------+\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.replace(\"Description\",Map(\"\"->\"UNKNOWN\"))\n",
    ".where(col(\"Description\")===\"UNKNOWN\")\n",
    ".select(\"Description\")\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complexDF = [complex: struct<Description: string, InvoiceNo: string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[complex: struct<Description: string, InvoiceNo: string>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.struct\n",
    "val complexDF = df.select(struct(\"Description\",\"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|split(Description,  )|\n",
      "+---------------------+\n",
      "| [WHITE, HANGING, ...|\n",
      "| [WHITE, METAL, LA...|\n",
      "+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.split\n",
    "\n",
    "df.select(split(col(\"Description\"),\" \")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|array_col[0]|\n",
      "+------------+\n",
      "|       WHITE|\n",
      "|       WHITE|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col(\"Description\"),\" \").alias(\"array_col\"))\n",
    ".selectExpr(\"array_col[0]\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|size(split(Description,  ))|\n",
      "+---------------------------+\n",
      "|                          5|\n",
      "|                          3|\n",
      "+---------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.size\n",
    "\n",
    "df.select(size(split(col(\"Description\"),\" \"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|array_contains(split(Description,  ), WHITE)|\n",
      "+--------------------------------------------+\n",
      "|                                        true|\n",
      "|                                        true|\n",
      "+--------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.array_contains\n",
    "df.select(array_contains(split(col(\"Description\"),\" \"),\"WHITE\"))\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+---------+--------+----------------------------------------+\n",
      "|Description                       |InvoiceNo|exploded|splitted                                |\n",
      "+----------------------------------+---------+--------+----------------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |WHITE   |[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|536365   |HANGING |[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "+----------------------------------+---------+--------+----------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{split,explode}\n",
    "\n",
    "df.withColumn(\"splitted\",split(col(\"Description\"),\" \"))\n",
    "  .withColumn(\"exploded\",explode(col(\"splitted\")))\n",
    "  .select(\"Description\",\"InvoiceNo\",\"exploded\",\"splitted\").show(2,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|splitted                                |\n",
      "+----------------------------------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "|[WHITE, METAL, LANTERN]                 |\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"splitted\",split(col(\"Description\"),\" \"))\n",
    ".limit(2).select(\"splitted\").show(2,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------+\n",
      "|splitted                                |exploded|\n",
      "+----------------------------------------+--------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|WHITE   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HANGING |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HEART   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|T-LIGHT |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HOLDER  |\n",
      "+----------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"splitted\",split(col(\"Description\"),\" \"))\n",
    ".limit(1).select(\"splitted\")\n",
    ".withColumn(\"exploded\",explode(col(\"splitted\")))\n",
    ".select(\"splitted\",\"exploded\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                 key| value|\n",
      "+--------------------+------+\n",
      "|WHITE HANGING HEA...|536365|\n",
      "| WHITE METAL LANTERN|536365|\n",
      "+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.map\n",
    "\n",
    "df.select(map(col(\"Description\"),\n",
    "             col(\"InvoiceNo\")).alias(\"complex_map\"))\n",
    ".selectExpr(\"explode(complex_map)\").show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
